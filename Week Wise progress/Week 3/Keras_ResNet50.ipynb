{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning it is incomplete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Cats & Dogs classes\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 100\n",
    "BATCH_SIZE_VALIDATION = 100\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "### \n",
    "### Below systax is available with TensorFlow 1.11 onwards but this upgrade is not available for Kaggle kernel yet\n",
    "###\n",
    "#import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "#import tensorflow as tf\n",
    "#from tf.keras.applications import ResNet50\n",
    "#from tf.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50\n",
    "* Notice that resnet50 folder has 2 pre-trained weights files... xyz_tf_kernels.h5 & xyz_tf_kernels_NOTOP.h5\n",
    "* The xyz_tf_kernels.h5 weights is useful for pure prediction of test image and this prediction will rely completely on ResNet50 pre-trained weights, i.e., it does not expected any training from our side\n",
    "* Out intention in this kernel is Transfer Learning by using ResNet50 pre-trained weights except its TOP layer, i.e., the xyz_tf_kernels_NOTOP.h5 weights... Use this weights as initial weight for training new layer using train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Our Transfer Learning Network Model Consisting of 2 Layers\n",
    "\n",
    "Here, we are preparing specification or blueprint of the TensorFlow DAG (directed acyclcic graph) for just the MODEL part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ABDUL REHMAN\\Desktop\\Spark IIT Rorkee\\Week 3\\Keras_ResNet50.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=4'>5</a>\u001b[0m \u001b[39m# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=5'>6</a>\u001b[0m \u001b[39m# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39madd(ResNet50(include_top \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, pooling \u001b[39m=\u001b[39;49m RESNET50_POOLING_AVERAGE, weights \u001b[39m=\u001b[39;49m resnet_weights_path))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39m# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ABDUL%20REHMAN/Desktop/Spark%20IIT%20Rorkee/Week%203/Keras_ResNet50.ipynb#ch0000007?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(NUM_CLASSES, activation \u001b[39m=\u001b[39m DENSE_LAYER_ACTIVATION))\n",
      "File \u001b[1;32mc:\\Users\\ABDUL REHMAN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\resnet.py:458\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m   x \u001b[39m=\u001b[39m stack1(x, \u001b[39m256\u001b[39m, \u001b[39m6\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m stack1(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m \u001b[39mreturn\u001b[39;00m ResNet(stack_fn, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mresnet50\u001b[39m\u001b[39m'\u001b[39m, include_top, weights,\n\u001b[0;32m    459\u001b[0m               input_tensor, input_shape, pooling, classes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ABDUL REHMAN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\resnet.py:125\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnknown argument(s): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (kwargs,))\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (weights \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m} \u001b[39mor\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(weights)):\n\u001b[1;32m--> 125\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe `weights` argument should be either \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    126\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m`None` (random initialization), `imagenet` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    127\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(pre-training on ImageNet), \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    128\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mor the path to the weights file to be loaded.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m include_top \u001b[39mand\u001b[39;00m classes \u001b[39m!=\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m    131\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    132\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
     ]
    }
   ],
   "source": [
    "#Still not talking about our train/test data or any pre-processing.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3424c8d5d5d4023d4e99034e313d6393514efb28456fdd7c218e89ee93bab514"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
